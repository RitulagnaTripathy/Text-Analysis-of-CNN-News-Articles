{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLACKCOFFER TEXT ANALYSIS\n",
    "\n",
    "SUBMITTED BY: RITULAGNA TRIPATHY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SENTIMENT ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of given stopwords\n",
    "\n",
    "stopword_files = [\"StopWords\\StopWords_Auditor.txt\", \"StopWords\\StopWords_Currencies.txt\",\n",
    "                \"StopWords\\StopWords_DatesandNumbers.txt\", \"StopWords\\StopWords_Generic.txt\",\n",
    "                \"StopWords\\StopWords_GenericLong.txt\",\"StopWords\\StopWords_Geographic.txt\",\"StopWords\\StopWords_Names.txt\"]\n",
    "with open(\"stopwords.txt\", \"w\") as new_created_file:\n",
    "    for name in stopword_files:\n",
    "        with open(name) as file:\n",
    "            for line in file:\n",
    "               new_created_file.write(line)\n",
    "\n",
    "stopwords_given = []\n",
    "data = open('stopwords.txt', 'r').read()\n",
    "data = data.replace(\"\\n\",\" \")\n",
    "stopwords_given = data.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning using stopwords list\n",
    "def clean_stopwords(dataset,stopwords_given):\n",
    "   data = ' '.join([word for word in dataset.split() if word.lower() not in stopwords_given])\n",
    "   return data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a dictionary of Positive & Negative words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_words = open('MasterDictionary\\positive-words.txt','r', encoding=\"utf8\").read()\n",
    "pos_words = pos_words.replace(\"\\n\",\" \")\n",
    "pos_words = pos_words.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_words = open(\"MasterDictionary/negative-words.txt\",'r').read()\n",
    "neg_words = neg_words.replace(\"\\n\",\" \")\n",
    "neg_words = neg_words.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0      37  https://insights.blackcoffer.com/ai-in-healthc...             NaN   \n",
       "1      38  https://insights.blackcoffer.com/what-if-the-c...             NaN   \n",
       "2      39  https://insights.blackcoffer.com/what-jobs-wil...             NaN   \n",
       "3      40  https://insights.blackcoffer.com/will-machine-...             NaN   \n",
       "4      41  https://insights.blackcoffer.com/will-ai-repla...             NaN   \n",
       "\n",
       "   NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0             NaN             NaN                 NaN                  NaN   \n",
       "1             NaN             NaN                 NaN                  NaN   \n",
       "2             NaN             NaN                 NaN                  NaN   \n",
       "3             NaN             NaN                 NaN                  NaN   \n",
       "4             NaN             NaN                 NaN                  NaN   \n",
       "\n",
       "   PERCENTAGE OF COMPLEX WORDS  FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                          NaN        NaN                               NaN   \n",
       "1                          NaN        NaN                               NaN   \n",
       "2                          NaN        NaN                               NaN   \n",
       "3                          NaN        NaN                               NaN   \n",
       "4                          NaN        NaN                               NaN   \n",
       "\n",
       "   COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                 NaN         NaN                NaN                NaN   \n",
       "1                 NaN         NaN                NaN                NaN   \n",
       "2                 NaN         NaN                NaN                NaN   \n",
       "3                 NaN         NaN                NaN                NaN   \n",
       "4                 NaN         NaN                NaN                NaN   \n",
       "\n",
       "   AVG WORD LENGTH  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  "
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data = pd.read_excel(\"Output Data Structure.xlsx\")\n",
    "output_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score = []\n",
    "neg_score = []\n",
    "pol_score = []\n",
    "sub_score = []\n",
    "avg_sen_len = []\n",
    "percentage_complex_words = []\n",
    "fog_index = []\n",
    "avg_words_per_sen = []\n",
    "count_complex_words = []\n",
    "word_count = []\n",
    "syllable_per_word = []\n",
    "personal_pronouns = []\n",
    "avg_word_len = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of different scores\n",
    "\n",
    "for i in range(114):\n",
    "\n",
    "    url_id = output_data._get_value(i,'URL_ID')\n",
    "    file_path = f\"{int(url_id)}.txt\"\n",
    "    dataset = open(file_path,'r',encoding='utf8').read()\n",
    "    dataset = clean_stopwords(dataset,stopwords_given)\n",
    "    words_dataset = dataset.split(\" \")\n",
    "    \n",
    "    positive_score = 0\n",
    "    negative_score = 0\n",
    "    total_words_after_cleaning = len(words_dataset)\n",
    "\n",
    "    for i in range (len(words_dataset)):\n",
    "        if words_dataset[i] in pos_words:\n",
    "            positive_score +=1\n",
    "        elif words_dataset[i] in neg_words:\n",
    "            negative_score +=1\n",
    "    \n",
    "\n",
    "    polarity_score = (positive_score - negative_score)/ ((positive_score + negative_score) + 0.000001)\n",
    "    subjectivity_score = (positive_score + negative_score)/ ((total_words_after_cleaning) + 0.000001)\n",
    "\n",
    "    pos_score.append(round(positive_score))\n",
    "    neg_score.append(round(negative_score))\n",
    "    pol_score.append(round(polarity_score,2))\n",
    "    sub_score.append(round(subjectivity_score,2))\n",
    "\n",
    "   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANALYSIS OF READABILITY**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Cleaning\n",
    "\n",
    "#nltk stopwords\n",
    "stopwords = open('nltk stopwords.txt','r', encoding='utf8').read()\n",
    "stopwords = stopwords.split()\n",
    "\n",
    "def clean_data(dataset):\n",
    "    dataset = re.sub('[^a-zA-Z]', ' ', dataset) #To remove non-alphabetical characters\n",
    "    dataset = re.sub(r'\\s+', ' ', dataset) #To remove more than one blank space\n",
    "    words_dataset = dataset.lower().split(\" \")\n",
    "    return words_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(word):\n",
    "    word = word.lower()\n",
    "    count = 0\n",
    "    vowels = [\"a\",\"e\",\"i\",\"o\",\"u\",\"y\"]\n",
    "    exceptions = (\"es\",\"ed\",\"e\")\n",
    "    \n",
    "    if word[0] in vowels:\n",
    "        count += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "                count += 1\n",
    "        if word.endswith(exceptions):\n",
    "            count -= 1\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(114):\n",
    "\n",
    "    url_id = output_data._get_value(i,'URL_ID')\n",
    "    file_path = f\"{int(url_id)}.txt\"\n",
    "    dataset = open(file_path,'r',encoding='utf8').read()\n",
    "\n",
    "    sen_dataset = dataset.split(\".\")\n",
    "    total_sen = len(sen_dataset) #Counting total no of sentences\n",
    "\n",
    "    dataset = re.sub(r'[^\\w\\s]', ' ', dataset) #To remove non-alphanumeric characters\n",
    "    dataset = re.sub(r'\\s+', ' ', dataset) #To remove more than one blank space\n",
    "    words_dataset = dataset.split(\" \")\n",
    "    \n",
    "    total_words = len(words_dataset) #Counting total no of words\n",
    "\n",
    "    #Count of personal pronouns\n",
    "    pronouns = ['I','we','We','my','My','ours','our','Our','us']\n",
    "    count_pronoun = 0\n",
    "\n",
    "    #Calculation of average word length\n",
    "    character_count = 0\n",
    "\n",
    "    for word in words_dataset:\n",
    "        character_count += len(word)\n",
    "        if word in pronouns:\n",
    "            count_pronoun += 1\n",
    "\n",
    "    average_word_len = character_count/total_words\n",
    "    avg_word_len.append(round(average_word_len))\n",
    "\n",
    "    personal_pronouns.append(count_pronoun)\n",
    "\n",
    "    #Clean word count\n",
    "    clean_dataset = []\n",
    "    for word in words_dataset:\n",
    "        if word not in stopwords:\n",
    "            clean_dataset.append(word)\n",
    "    \n",
    "    word_count.append(len(clean_dataset))\n",
    "\n",
    "    #Calculation of no of complex words & count of syllables per word\n",
    "    syllables = 0\n",
    "    s_count = 0\n",
    "    complex_words = 0\n",
    "\n",
    "    for i in range(total_words):\n",
    "        syllables = syllable_count(words_dataset[i])\n",
    "        if (syllables>2):\n",
    "            complex_words += 1\n",
    "\n",
    "        s_count+=syllables\n",
    "    \n",
    "    count_complex_words.append(complex_words)\n",
    "\n",
    "    syllable_count_per_word = s_count/total_words\n",
    "    syllable_per_word.append(round(syllable_count_per_word))\n",
    "\n",
    "    #Calculation of percentage of complex words\n",
    "    percentage_of_complex_words = (complex_words/total_words)*100\n",
    "    percentage_complex_words.append(round(percentage_of_complex_words))\n",
    "\n",
    "    #Calculation of average words per sentence\n",
    "    average_words_per_sen = total_words/total_sen\n",
    "    avg_words_per_sen.append(round(average_words_per_sen))\n",
    "\n",
    "    #Calculation of average sentence length\n",
    "    average_sentence_length = average_words_per_sen\n",
    "    avg_sen_len.append(round(average_sentence_length))\n",
    "\n",
    "    #Calculation of fog index\n",
    "    fog_i = (average_sentence_length+percentage_of_complex_words)*0.4\n",
    "    fog_index.append(round(fog_i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>54</td>\n",
       "      <td>25</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.08</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>386</td>\n",
       "      <td>1234</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>45</td>\n",
       "      <td>28</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.11</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>190</td>\n",
       "      <td>845</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>58</td>\n",
       "      <td>29</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.10</td>\n",
       "      <td>20</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>332</td>\n",
       "      <td>1083</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.07</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>216</td>\n",
       "      <td>974</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>40</td>\n",
       "      <td>18</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.07</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>270</td>\n",
       "      <td>1071</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>146</td>\n",
       "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>182</td>\n",
       "      <td>625</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>147</td>\n",
       "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.06</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>182</td>\n",
       "      <td>733</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>148</td>\n",
       "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>198</td>\n",
       "      <td>740</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>149</td>\n",
       "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.08</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>135</td>\n",
       "      <td>380</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>150</td>\n",
       "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.11</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>169</td>\n",
       "      <td>663</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     URL_ID                                                URL  \\\n",
       "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
       "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
       "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
       "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
       "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
       "..      ...                                                ...   \n",
       "109     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
       "110     147  https://insights.blackcoffer.com/the-future-of...   \n",
       "111     148  https://insights.blackcoffer.com/big-data-anal...   \n",
       "112     149  https://insights.blackcoffer.com/business-anal...   \n",
       "113     150  https://insights.blackcoffer.com/challenges-an...   \n",
       "\n",
       "     POSITIVE SCORE  NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  \\\n",
       "0                54              25            0.37                0.08   \n",
       "1                45              28            0.23                0.11   \n",
       "2                58              29            0.33                0.10   \n",
       "3                38              14            0.46                0.07   \n",
       "4                40              18            0.38                0.07   \n",
       "..              ...             ...             ...                 ...   \n",
       "109              22              22            0.00                0.09   \n",
       "110              28               6            0.65                0.06   \n",
       "111              27              33           -0.10                0.09   \n",
       "112              24               2            0.85                0.08   \n",
       "113              30              33           -0.05                0.11   \n",
       "\n",
       "     AVG SENTENCE LENGTH  PERCENTAGE OF COMPLEX WORDS  FOG INDEX  \\\n",
       "0                     24                           21         18   \n",
       "1                     21                           13         13   \n",
       "2                     20                           19         16   \n",
       "3                     19                           13         13   \n",
       "4                     22                           15         15   \n",
       "..                   ...                          ...        ...   \n",
       "109                   17                           19         14   \n",
       "110                   21                           16         15   \n",
       "111                   16                           17         13   \n",
       "112                   22                           22         18   \n",
       "113                   16                           15         13   \n",
       "\n",
       "     AVG NUMBER OF WORDS PER SENTENCE  COMPLEX WORD COUNT  WORD COUNT  \\\n",
       "0                                  24                 386        1234   \n",
       "1                                  21                 190         845   \n",
       "2                                  20                 332        1083   \n",
       "3                                  19                 216         974   \n",
       "4                                  22                 270        1071   \n",
       "..                                ...                 ...         ...   \n",
       "109                                17                 182         625   \n",
       "110                                21                 182         733   \n",
       "111                                16                 198         740   \n",
       "112                                22                 135         380   \n",
       "113                                16                 169         663   \n",
       "\n",
       "     SYLLABLE PER WORD  PERSONAL PRONOUNS  AVG WORD LENGTH  \n",
       "0                    2                  6                6  \n",
       "1                    1                 10                5  \n",
       "2                    1                  5                5  \n",
       "3                    1                 24                5  \n",
       "4                    1                 20                5  \n",
       "..                 ...                ...              ...  \n",
       "109                  1                 11                5  \n",
       "110                  1                  4                5  \n",
       "111                  1                  4                5  \n",
       "112                  2                  2                6  \n",
       "113                  1                 12                5  \n",
       "\n",
       "[114 rows x 15 columns]"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entering all the calculated data to the dataframe\n",
    "\n",
    "output_data['POSITIVE SCORE']=pos_score\n",
    "output_data['NEGATIVE SCORE']=neg_score\n",
    "output_data['POLARITY SCORE']=pol_score\n",
    "output_data['SUBJECTIVITY SCORE']=sub_score\n",
    "output_data['AVG SENTENCE LENGTH']=avg_sen_len\n",
    "output_data['PERCENTAGE OF COMPLEX WORDS']=percentage_complex_words\n",
    "output_data['FOG INDEX']=fog_index\n",
    "output_data['AVG NUMBER OF WORDS PER SENTENCE']=avg_words_per_sen\n",
    "output_data['COMPLEX WORD COUNT']=count_complex_words\n",
    "output_data['SYLLABLE PER WORD']=syllable_per_word\n",
    "output_data['WORD COUNT']=word_count\n",
    "output_data['PERSONAL PRONOUNS']=personal_pronouns\n",
    "output_data['AVG WORD LENGTH']=avg_word_len\n",
    "\n",
    "output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data.to_excel(\"Output.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
